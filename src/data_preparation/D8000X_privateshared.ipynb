{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import copy\n",
    "#from src.utils.utils import ensure_alternating_roles\n",
    "\n",
    "path: str = ('../../data/processed/privateshared_old_processed.jsonl')\n",
    "data = pd.read_json(path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_alternating_roles(messages, cull_system_message: bool = True):\n",
    "    \"\"\"\n",
    "    The messages format assumes alternating roles of user and assistant. This method checks, if this constraint\n",
    "    is satisfied. If this is not the case and there are consecutive user or assistant messages,\n",
    "    then these are merged into a single one.\n",
    "\n",
    "    :param cull_system_message:\n",
    "    :param messages: to be checked\n",
    "    :return: a new messages object with the alternating roles ensured\n",
    "    \"\"\"\n",
    "    consec_msg = 0\n",
    "    _messages = copy.deepcopy(messages)\n",
    "\n",
    "    if cull_system_message:\n",
    "        if _messages[0]['role'] == \"system\" and not _messages[0][\"content\"]:\n",
    "            del _messages[0]\n",
    "\n",
    "    def is_same_role(msg1, msg2):\n",
    "        return msg1[\"role\"] == msg2[\"role\"]\n",
    "\n",
    "    delimiter = \"\\n\\n\"\n",
    "\n",
    "    def join_content(msg1, msg2):\n",
    "        return f\"{msg1['content']}{delimiter}{msg2['content']}\"\n",
    "\n",
    "    if len(_messages) <= 1:\n",
    "        return _messages\n",
    "\n",
    "    def is_valid(idx):\n",
    "        return idx < len(_messages)\n",
    "\n",
    "    msg_idx = 1\n",
    "    while is_valid(msg_idx):\n",
    "        prev_message = _messages[msg_idx - 1]\n",
    "        message = _messages[msg_idx]\n",
    "        if is_same_role(prev_message, message):\n",
    "            warn_msg = (f\"Found consecutive role assignments. These will be merged into one:\\n\"\n",
    "                        f\"{prev_message}\\n\"\n",
    "                        f\"{message}\")\n",
    "            #logger.warning(warn_msg)\n",
    "            #print(\"X\")\n",
    "            consec_msg += 1\n",
    "            prev_message['content'] = join_content(prev_message, message)\n",
    "            del _messages[msg_idx]\n",
    "        else:\n",
    "            msg_idx += 1\n",
    "    #print(f\"{consec_msg} consecutive messages have been merged!\")\n",
    "    return _messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_data_psh1(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splits privateshared dialogues in such a way that all probing blocks remain together.\n",
    "    \"\"\"\n",
    "    result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        chat = row['chat']\n",
    "        game = row['game']\n",
    "\n",
    "        chat_last_index = len(chat)-1\n",
    "\n",
    "        for i, item in enumerate(chat):\n",
    "            if item['type'] == 'send message':\n",
    "                for column in data.columns:\n",
    "                    if chat[:i]:\n",
    "                        if column == 'chat':\n",
    "                            result_data[column].append(chat[:i]) # append everything above \"send message\"\n",
    "                        else: \n",
    "                            result_data[column].append(row[column])\n",
    "                         \n",
    "            else:\n",
    "                if i == chat_last_index: # maybe should test whether last entry is also assistant?\n",
    "                    for key in data.columns:\n",
    "                            result_data[key].append(row[key])\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_qa_data_psh2(data: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Splits privateshared dialogues in such a way that only a sample of each probing block remains together.\n",
    "#     \"\"\"\n",
    "#     result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "#     for i, row in data.iterrows():\n",
    "#         chat = row['chat']\n",
    "#         chat_last_index = len(chat)-1\n",
    "#         messages = []\n",
    "#         probes = []\n",
    "#         for i, item in enumerate(chat):\n",
    "#             if \"message\" in item[\"type\"]:\n",
    "#                 messages.append(item)\n",
    "#             elif \"probe\" in item[\"type\"]:\n",
    "#                 if i != chat_last_index:\n",
    "#                     if \"probe\" in chat[i+1][\"type\"]: # if next turn is also part of probing\n",
    "#                         probes.append(item)\n",
    "#                     else:\n",
    "#                         probes.append(item)\n",
    "#                         for column in data.columns:\n",
    "#                             if column == 'chat':\n",
    "#                                 # sample probes here\n",
    "#                                 result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "#                                 probes = []\n",
    "#                             else: \n",
    "#                                 result_data[column].append(row[column])\n",
    "                            \n",
    "                        \n",
    "#                 else:\n",
    "#                     for column in data.columns:\n",
    "#                         probes.append(item)\n",
    "#                         if column == 'chat':\n",
    "#                             result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "#                         else: \n",
    "#                             result_data[column].append(row[column])\n",
    "\n",
    "\n",
    "#     return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_data_psh3(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splits privateshared dialogues in such a way that all probing blocks remain together and only one probing block remains.\n",
    "    \"\"\"\n",
    "    result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        chat = row['chat']\n",
    "        chat_last_index = len(chat)-1\n",
    "        messages = []\n",
    "        probes = []\n",
    "        for i, item in enumerate(chat):\n",
    "            if \"message\" in item[\"type\"]:\n",
    "                messages.append(item)\n",
    "            elif \"probe\" in item[\"type\"]:\n",
    "                if i != chat_last_index:\n",
    "                    if \"probe\" in chat[i+1][\"type\"]: # if next turn is also part of probing\n",
    "                        probes.append(item)\n",
    "                    else:\n",
    "                        probes.append(item)\n",
    "                        for column in data.columns:\n",
    "                            if column == 'chat':\n",
    "                                result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "                                probes = []\n",
    "                            else: \n",
    "                                result_data[column].append(row[column])\n",
    "                            \n",
    "                        \n",
    "                else:\n",
    "                    for column in data.columns:\n",
    "                        \n",
    "                        if column == 'chat':\n",
    "                            probes.append(item)\n",
    "                            result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "                            probes = []\n",
    "                        else: \n",
    "                            result_data[column].append(row[column])\n",
    "\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "2497 336\n"
     ]
    }
   ],
   "source": [
    "save_path: str = '../../data/training_data/D8000p1.csv'\n",
    "data_successful = data[data.Success == 1]\n",
    "print(len(data_successful))\n",
    "data_successful.chat = data_successful.chat.apply(ensure_alternating_roles)\n",
    "result = prepare_qa_data_psh1(data_successful)\n",
    "data_collapsed = pd.DataFrame(result)\n",
    "print(len(data), len(data_collapsed))\n",
    "#data_collapsed[[\"chat\"]].iloc[:15].to_csv(\"psh1.csv\")\n",
    "\n",
    "data_collapsed.to_csv(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "2497 336\n"
     ]
    }
   ],
   "source": [
    "save_path: str = '../../data/training_data/D8000p3.csv'\n",
    "data_successful = data[data.Success == 1]\n",
    "print(len(data_successful))\n",
    "\n",
    "result = prepare_qa_data_psh3(data_successful)\n",
    "data_collapsed = pd.DataFrame(result)\n",
    "\n",
    "# important to merge *after* splitting so that the first probe question is not automatically appended to the prompt\n",
    "data_collapsed.chat = data_collapsed.chat.apply(ensure_alternating_roles)\n",
    "\n",
    "print(len(data), len(data_collapsed))\n",
    "#data_collapsed[[\"chat\"]].iloc[:33].to_csv(\"psh3_ear.csv\")\n",
    "\n",
    "data_collapsed.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
