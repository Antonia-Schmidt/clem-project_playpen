{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:01:31.634463Z",
     "start_time": "2025-01-23T11:01:25.806240Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import copy\n",
    "#from src.utils.utils import ensure_alternating_roles\n",
    "\n",
    "path: str = ('../../data/processed/privateshared_old_processed.jsonl')\n",
    "data = pd.read_json(path, lines=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T11:27:55.184896Z",
     "start_time": "2024-12-23T11:27:55.144484Z"
    }
   },
   "cell_type": "code",
   "source": "data.benchmark_version.unique()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['v0.9', 'v1.0'], dtype=object)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 237
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:54:34.033967Z",
     "start_time": "2024-12-22T13:54:34.019168Z"
    }
   },
   "source": [
    "def ensure_alternating_roles(messages, cull_system_message: bool = True):\n",
    "    \"\"\"\n",
    "    The messages format assumes alternating roles of user and assistant. This method checks, if this constraint\n",
    "    is satisfied. If this is not the case and there are consecutive user or assistant messages,\n",
    "    then these are merged into a single one.\n",
    "\n",
    "    :param cull_system_message:\n",
    "    :param messages: to be checked\n",
    "    :return: a new messages object with the alternating roles ensured\n",
    "    \"\"\"\n",
    "    consec_msg = 0\n",
    "    _messages = copy.deepcopy(messages)\n",
    "\n",
    "    if cull_system_message:\n",
    "        if _messages[0]['role'] == \"system\" and not _messages[0][\"content\"]:\n",
    "            del _messages[0]\n",
    "\n",
    "    def is_same_role(msg1, msg2):\n",
    "        return msg1[\"role\"] == msg2[\"role\"]\n",
    "\n",
    "    delimiter = \"\\n\\n\"\n",
    "\n",
    "    def join_content(msg1, msg2):\n",
    "        return f\"{msg1['content']}{delimiter}{msg2['content']}\"\n",
    "\n",
    "    if len(_messages) <= 1:\n",
    "        return _messages\n",
    "\n",
    "    def is_valid(idx):\n",
    "        return idx < len(_messages)\n",
    "\n",
    "    msg_idx = 1\n",
    "    while is_valid(msg_idx):\n",
    "        prev_message = _messages[msg_idx - 1]\n",
    "        message = _messages[msg_idx]\n",
    "        if is_same_role(prev_message, message):\n",
    "            warn_msg = (f\"Found consecutive role assignments. These will be merged into one:\\n\"\n",
    "                        f\"{prev_message}\\n\"\n",
    "                        f\"{message}\")\n",
    "            #logger.warning(warn_msg)\n",
    "            #print(\"X\")\n",
    "            consec_msg += 1\n",
    "            prev_message['content'] = join_content(prev_message, message)\n",
    "            del _messages[msg_idx]\n",
    "        else:\n",
    "            msg_idx += 1\n",
    "    #print(f\"{consec_msg} consecutive messages have been merged!\")\n",
    "    return _messages\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:56:41.420485Z",
     "start_time": "2024-12-22T13:56:41.413383Z"
    }
   },
   "source": [
    "def prepare_qa_data_psh1(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splits privateshared dialogues in such a way that all probing blocks remain together.\n",
    "    \"\"\"\n",
    "    result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        chat = row['chat']\n",
    "        game = row['game']\n",
    "\n",
    "        chat_last_index = len(chat)-1\n",
    "\n",
    "        for i, item in enumerate(chat):\n",
    "            if item['type'] == 'send message':\n",
    "                for column in data.columns:\n",
    "                    if chat[:i]:\n",
    "                        if column == 'chat':\n",
    "                            result_data[column].append(chat[:i]) # append everything above \"send message\"\n",
    "                        else: \n",
    "                            result_data[column].append(row[column])\n",
    "                         \n",
    "            else:\n",
    "                if i == chat_last_index: # maybe should test whether last entry is also assistant?\n",
    "                    for key in data.columns:\n",
    "                            result_data[key].append(row[key])\n",
    "    return result_data"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_qa_data_psh2(data: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Splits privateshared dialogues in such a way that only a sample of each probing block remains together.\n",
    "#     \"\"\"\n",
    "#     result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "#     for i, row in data.iterrows():\n",
    "#         chat = row['chat']\n",
    "#         chat_last_index = len(chat)-1\n",
    "#         messages = []\n",
    "#         probes = []\n",
    "#         for i, item in enumerate(chat):\n",
    "#             if \"message\" in item[\"type\"]:\n",
    "#                 messages.append(item)\n",
    "#             elif \"probe\" in item[\"type\"]:\n",
    "#                 if i != chat_last_index:\n",
    "#                     if \"probe\" in chat[i+1][\"type\"]: # if next turn is also part of probing\n",
    "#                         probes.append(item)\n",
    "#                     else:\n",
    "#                         probes.append(item)\n",
    "#                         for column in data.columns:\n",
    "#                             if column == 'chat':\n",
    "#                                 # sample probes here\n",
    "#                                 result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "#                                 probes = []\n",
    "#                             else: \n",
    "#                                 result_data[column].append(row[column])\n",
    "                            \n",
    "                        \n",
    "#                 else:\n",
    "#                     for column in data.columns:\n",
    "#                         probes.append(item)\n",
    "#                         if column == 'chat':\n",
    "#                             result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "#                         else: \n",
    "#                             result_data[column].append(row[column])\n",
    "\n",
    "\n",
    "#     return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_data_psh3(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splits privateshared dialogues in such a way that all probing blocks remain together and only one probing block remains.\n",
    "    \"\"\"\n",
    "    result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        chat = row['chat']\n",
    "        chat_last_index = len(chat)-1\n",
    "        messages = []\n",
    "        probes = []\n",
    "        for i, item in enumerate(chat):\n",
    "            if \"message\" in item[\"type\"]:\n",
    "                messages.append(item)\n",
    "            elif \"probe\" in item[\"type\"]:\n",
    "                if i != chat_last_index:\n",
    "                    if \"probe\" in chat[i+1][\"type\"]: # if next turn is also part of probing\n",
    "                        probes.append(item)\n",
    "                    else:\n",
    "                        probes.append(item)\n",
    "                        for column in data.columns:\n",
    "                            if column == 'chat':\n",
    "                                result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "                                probes = []\n",
    "                            else: \n",
    "                                result_data[column].append(row[column])\n",
    "                            \n",
    "                        \n",
    "                else:\n",
    "                    for column in data.columns:\n",
    "                        \n",
    "                        if column == 'chat':\n",
    "                            probes.append(item)\n",
    "                            result_data[column].append(messages + probes) # append everything above \"send message\"\n",
    "                            probes = []\n",
    "                        else: \n",
    "                            result_data[column].append(row[column])\n",
    "\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T13:56:59.112990Z",
     "start_time": "2024-12-22T13:56:59.076421Z"
    }
   },
   "source": [
    "save_path: str = '../../data/training_data/D8000p1.csv'\n",
    "data_successful = data[data.Success == 1]\n",
    "print(len(data_successful))\n",
    "data_successful.chat = data_successful.chat.apply(ensure_alternating_roles)\n",
    "result = prepare_qa_data_psh1(data_successful)\n",
    "data_collapsed = pd.DataFrame(result)\n",
    "print(len(data), len(data_collapsed))\n",
    "#data_collapsed[[\"chat\"]].iloc[:15].to_csv(\"psh1.csv\")\n",
    "\n",
    "#ata_collapsed.to_csv(save_path, index=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "2497 336\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "2497 336\n"
     ]
    }
   ],
   "source": [
    "save_path: str = '../../data/training_data/D8000p3.csv'\n",
    "data_successful = data[data.Success == 1]\n",
    "print(len(data_successful))\n",
    "\n",
    "result = prepare_qa_data_psh3(data_successful)\n",
    "data_collapsed = pd.DataFrame(result)\n",
    "\n",
    "# important to merge *after* splitting so that the first probe question is not automatically appended to the prompt\n",
    "data_collapsed.chat = data_collapsed.chat.apply(ensure_alternating_roles)\n",
    "\n",
    "print(len(data), len(data_collapsed))\n",
    "#data_collapsed[[\"chat\"]].iloc[:33].to_csv(\"psh3_ear.csv\")\n",
    "\n",
    "data_collapsed.to_csv(save_path, index=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rework of p1 -> D70001"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:38:04.118004Z",
     "start_time": "2024-12-22T17:38:04.109472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_probe_question_mask(chat: list) -> list:\n",
    "    probe_questions_indexes: list = []\n",
    "    is_probe: bool = False\n",
    "\n",
    "    for chat_idx, chat_item in enumerate(chat):\n",
    "        if chat_item['type'] == 'send message':\n",
    "            if is_probe:\n",
    "                is_probe = False\n",
    "        if chat_item['type'] == 'probe question':\n",
    "            if not is_probe:\n",
    "                is_probe = True\n",
    "            probe_questions_indexes.append(chat_idx)\n",
    "        if chat_item['type'] == 'probe answer':\n",
    "            probe_questions_indexes.append(chat_idx)\n",
    "\n",
    "    return probe_questions_indexes\n",
    "\n",
    "def prepare_qa_data_psh4(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "    \n",
    "    for idx, row in data.iterrows():\n",
    "        chat = row['chat']\n",
    "        probe_question_mask = get_probe_question_mask(chat)\n",
    "\n",
    "        chat_last_index = len(chat)\n",
    "\n",
    "        for i, item in enumerate(chat):\n",
    "            if i in probe_question_mask:\n",
    "                \n",
    "                # check that we are at the end of a probe block\n",
    "                if i+1 not in probe_question_mask:\n",
    "                    for key in data.columns:\n",
    "                        if key != 'chat':\n",
    "                            result_data[key].append(row[key])\n",
    "                        else:\n",
    "                            if i + 1 < chat_last_index:\n",
    "                                result_data[key].append(chat[:i + 1])\n",
    "                            else:\n",
    "                                result_data[key].append(row[key])     \n",
    "                continue\n",
    "                \n",
    "            if item['role'] == 'assistant':\n",
    "                for key in data.columns:\n",
    "                    if key != 'chat':\n",
    "                        result_data[key].append(row[key])\n",
    "                    else:\n",
    "                        if i + 1 < chat_last_index:\n",
    "                            result_data[key].append(chat[:i + 1])\n",
    "                        else:\n",
    "                            result_data[key].append(row[key])\n",
    "    return result_data"
   ],
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:38:04.833650Z",
     "start_time": "2024-12-22T17:38:04.709850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_successful = data[data.Success == 1]\n",
    "print(len(data_successful))\n",
    "\n",
    "result = prepare_qa_data_psh4(data_successful)\n",
    "data_collapsed_ph4 = pd.DataFrame(result)\n",
    "\n",
    "# important to merge *after* splitting so that the first probe question is not automatically appended to the prompt\n",
    "data_collapsed_ph4.chat = data_collapsed_ph4.chat.apply(ensure_alternating_roles)\n",
    "\n",
    "print(len(data), len(data_collapsed_ph4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "2497 631\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:38:07.235980Z",
     "start_time": "2024-12-22T17:38:07.107587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path: str = '../../data/training_data/D70001.csv'\n",
    "data_collapsed_ph4.to_csv(save_path, index=False)"
   ],
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# P70002"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:36.459779Z",
     "start_time": "2024-12-22T17:50:36.450160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def get_probe_question_mask(chat: list) -> (list, list):\n",
    "    probe_questions_indexes: list = []\n",
    "    probe_mask: list = []\n",
    "    is_probe: bool = False\n",
    "\n",
    "    for chat_idx, chat_item in enumerate(chat):\n",
    "        if chat_item['type'] == 'send message':\n",
    "            if is_probe:\n",
    "                is_probe = False\n",
    "        if chat_item['type'] == 'probe question':\n",
    "            if not is_probe:\n",
    "                is_probe = True\n",
    "            probe_questions_indexes.append(chat_idx)\n",
    "            probe_mask.append(chat_idx)\n",
    "        if chat_item['type'] == 'probe answer':\n",
    "            probe_mask.append(chat_idx)\n",
    "            \n",
    "    return probe_questions_indexes, probe_mask\n",
    "\n",
    "def sample(idx_list: list, fraction: float) -> list:\n",
    "    num_samples: int = int(len(idx_list) * (fraction/2))\n",
    "    new_samples = random.sample(idx_list, num_samples)\n",
    "    \n",
    "    return_samples = []\n",
    "    \n",
    "    for n in new_samples:\n",
    "        if n%2 == 0:\n",
    "            return_samples.append(n)\n",
    "            return_samples.append(n-1)\n",
    "        else:\n",
    "            return_samples.append(n)\n",
    "            return_samples.append(n+1)\n",
    "    \n",
    "    return list(set(return_samples))\n",
    "            \n",
    "\n",
    "def prepare_qa_data_psh2(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    result_data: pd.DataFrame = {key: [] for key in data.columns}\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        chat = row['chat']\n",
    "        probe_question_mask, _ = get_probe_question_mask(chat)\n",
    "        probe_questions_to_drop = sample(probe_question_mask, 0.9)\n",
    "        \n",
    "        reduced_chat = [c for i, c in enumerate(chat) if i not in probe_questions_to_drop]\n",
    "        \n",
    "        _, probe_mask = get_probe_question_mask(reduced_chat)\n",
    "        chat_last_index = len(reduced_chat)\n",
    "\n",
    "        for i, item in enumerate(reduced_chat):\n",
    "            if i in probe_mask:\n",
    "\n",
    "                # check that we are at the end of a probe block\n",
    "                if i+1 not in probe_mask:\n",
    "                    for key in data.columns:\n",
    "                        if key != 'chat':\n",
    "                            result_data[key].append(row[key])\n",
    "                        else:\n",
    "                            if i + 1 < chat_last_index:\n",
    "                                result_data[key].append(reduced_chat[:i + 1])\n",
    "                            else:\n",
    "                                result_data[key].append(row[key])\n",
    "                continue\n",
    "\n",
    "            if item['role'] == 'assistant':\n",
    "                for key in data.columns:\n",
    "                    if key != 'chat':\n",
    "                        result_data[key].append(row[key])\n",
    "                    else:\n",
    "                        if i + 1 < chat_last_index:\n",
    "                            result_data[key].append(reduced_chat[:i + 1])\n",
    "                        else:\n",
    "                            result_data[key].append(row[key])\n",
    "    return result_data"
   ],
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:36.996320Z",
     "start_time": "2024-12-22T17:50:36.901690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_successful = data[data.Success == 1]\n",
    "print(len(data_successful))\n",
    "\n",
    "result = prepare_qa_data_psh2(data_successful)\n",
    "data_collapsed_ph2 = pd.DataFrame(result)\n",
    "\n",
    "# important to merge *after* splitting so that the first probe question is not automatically appended to the prompt\n",
    "data_collapsed_ph2.chat = data_collapsed_ph2.chat.apply(ensure_alternating_roles)\n",
    "\n",
    "print(len(data_collapsed_ph4), len(data_collapsed_ph2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "631 629\n"
     ]
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:37.014719Z",
     "start_time": "2024-12-22T17:50:36.998001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lenC = 0\n",
    "for i, r in data_collapsed_ph4.iterrows():\n",
    "    lenC += len(r['chat'])"
   ],
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:37.294874Z",
     "start_time": "2024-12-22T17:50:37.291942Z"
    }
   },
   "cell_type": "code",
   "source": "lenC ",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63780"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:37.583028Z",
     "start_time": "2024-12-22T17:50:37.572778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lenB = 0\n",
    "for i, r in data_collapsed_ph2.iterrows():\n",
    "    lenB += len(r['chat'])"
   ],
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T17:50:38.137468Z",
     "start_time": "2024-12-22T17:50:38.135022Z"
    }
   },
   "cell_type": "code",
   "source": "lenB",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39842"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:01:42.601736Z",
     "start_time": "2025-01-23T11:01:42.595474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path: str = '../../data/training_data/D70002.csv'\n",
    "#data_collapsed_ph2.to_csv(save_path, index=False)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:01:43.047664Z",
     "start_time": "2025-01-23T11:01:42.959316Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(save_path)",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:01:46.332764Z",
     "start_time": "2025-01-23T11:01:46.313670Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            game benchmark_version  game_id  \\\n",
       "0  privateshared              v0.9        4   \n",
       "1  privateshared              v0.9        4   \n",
       "2  privateshared              v0.9        4   \n",
       "3  privateshared              v0.9        4   \n",
       "4  privateshared              v0.9        4   \n",
       "\n",
       "                                model        experiment    episode  Aborted  \\\n",
       "0  claude-v1.3-t0.0--claude-v1.3-t0.0  0_travel-booking  episode_4        0   \n",
       "1  claude-v1.3-t0.0--claude-v1.3-t0.0  0_travel-booking  episode_4        0   \n",
       "2  claude-v1.3-t0.0--claude-v1.3-t0.0  0_travel-booking  episode_4        0   \n",
       "3  claude-v1.3-t0.0--claude-v1.3-t0.0  0_travel-booking  episode_4        0   \n",
       "4  claude-v1.3-t0.0--claude-v1.3-t0.0  0_travel-booking  episode_4        0   \n",
       "\n",
       "   Lose  Success                                               chat  \\\n",
       "0     0        1  [{'role': 'user', 'content': 'You are a custom...   \n",
       "1     0        1  [{'role': 'user', 'content': 'You are a custom...   \n",
       "2     0        1  [{'role': 'user', 'content': 'You are a custom...   \n",
       "3     0        1  [{'role': 'user', 'content': 'You are a custom...   \n",
       "4     0        1  [{'role': 'user', 'content': 'You are a custom...   \n",
       "\n",
       "                                              target  \\\n",
       "0  {'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...   \n",
       "1  {'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...   \n",
       "2  {'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...   \n",
       "3  {'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...   \n",
       "4  {'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...   \n",
       "\n",
       "                                                text  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>benchmark_version</th>\n",
       "      <th>game_id</th>\n",
       "      <th>model</th>\n",
       "      <th>experiment</th>\n",
       "      <th>episode</th>\n",
       "      <th>Aborted</th>\n",
       "      <th>Lose</th>\n",
       "      <th>Success</th>\n",
       "      <th>chat</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privateshared</td>\n",
       "      <td>v0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-v1.3-t0.0--claude-v1.3-t0.0</td>\n",
       "      <td>0_travel-booking</td>\n",
       "      <td>episode_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a custom...</td>\n",
       "      <td>{'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>privateshared</td>\n",
       "      <td>v0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-v1.3-t0.0--claude-v1.3-t0.0</td>\n",
       "      <td>0_travel-booking</td>\n",
       "      <td>episode_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a custom...</td>\n",
       "      <td>{'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>privateshared</td>\n",
       "      <td>v0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-v1.3-t0.0--claude-v1.3-t0.0</td>\n",
       "      <td>0_travel-booking</td>\n",
       "      <td>episode_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a custom...</td>\n",
       "      <td>{'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>privateshared</td>\n",
       "      <td>v0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-v1.3-t0.0--claude-v1.3-t0.0</td>\n",
       "      <td>0_travel-booking</td>\n",
       "      <td>episode_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a custom...</td>\n",
       "      <td>{'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>privateshared</td>\n",
       "      <td>v0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>claude-v1.3-t0.0--claude-v1.3-t0.0</td>\n",
       "      <td>0_travel-booking</td>\n",
       "      <td>episode_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a custom...</td>\n",
       "      <td>{'from': 'Stockholm', 'to': 'Madrid', 'by': 'P...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:02:07.740724Z",
     "start_time": "2025-01-23T11:02:07.729485Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.text.iloc[10])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a customer of a travel agency. Here is a description of the details of the travel you want to make:\n",
      "\n",
      "WHAT: Travel\n",
      "FROM: Stockholm\n",
      "TO: Madrid\n",
      "BY: Plane\n",
      "CLASS: The most comfortable\n",
      "WHEN: On April 10\n",
      "\n",
      "The travel agent does not know about it yet. \n",
      "\n",
      "Questions from the travel agent will start with TRAVEL-AGENT. Please reply in the form: ANSWER: <some text>\n",
      "\n",
      "I will also ask you questions. These questions will start with ME: . Please answer these questions with: ASIDE: <some text>\n",
      "\n",
      "Important: Give short, direct answers!\n",
      "\n",
      "Let us start.\n",
      "\n",
      "ME:  Does the travel agent already know your origin? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Does the travel agent already know your destination? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Is the travel agent aware of your means of transportation? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Do you think the travel agent knows in which class the trip will happen? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you already mentioned the dates of your trip to the travel agent? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "TRAVEL-AGENT: When are you leaving?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANSWER: On April 10<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Is the travel agent aware of your origin? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you informed the travel agent about your destination? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Does the travel agent know how you wish to travel? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Does the travel agent know your preference for class? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you already mentioned the dates of your trip to the travel agent? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "TRAVEL-AGENT: What is the origin of your trip?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANSWER: Stockholm<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you already mentioned the origin of your trip to the travel agent? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Does the travel agent know where you want to go to? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Has the travel agent been informed about your preferred means of transportation? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you informed the travel agent about your class preference? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  If I asked the travel agent when are you travelling, would he or she know the answer? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "TRAVEL-AGENT: Please inform your destination.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANSWER: Madrid<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Does the travel agent know where your trip is starting? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Do you believe that the travel agent is aware of where you are going? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  If I asked the travel agent how you are travelling, would he or she know the answer? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Do you think the travel agent knows in which class the trip will happen? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you already mentioned the dates of your trip to the travel agent? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "TRAVEL-AGENT: Please let me know what kind of transport you want.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANSWER: Plane<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Do you believe that the travel agent is aware of your place of departure? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you informed the travel agent about your destination? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Does the travel agent know how you wish to travel? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Do you think the travel agent knows in which class the trip will happen? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Do you believe that the travel agent is aware of when you are travelling? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "TRAVEL-AGENT: Please inform the class I should book for you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ANSWER: The most comfortable<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Have you informed the travel agent about the place of departure? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  If I asked the travel agent where you want to go, would he or she know the answer? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Has the travel agent been informed about your preferred means of transportation? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Is the travel agent aware of which class you would like to book? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ME:  Is the travel agent aware of the dates of your trip? Please answer yes or no.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ASIDE: Yes<|eot_id|>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
