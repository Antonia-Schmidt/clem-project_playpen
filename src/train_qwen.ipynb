{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/project/envs/qwen-train-kernel/bin/pip\", line 5, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
      "    from pip._internal.cli.autocompletion import autocomplete\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py\", line 12, in <module>\n",
      "    from pip._internal.metadata import get_default_environment\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_internal/metadata/__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_internal/metadata/base.py\", line 21, in <module>\n",
      "    from pip._vendor.packaging.requirements import Requirement\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_vendor/packaging/requirements.py\", line 10, in <module>\n",
      "    from pip._vendor.pyparsing import (  # noqa\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_vendor/pyparsing/__init__.py\", line 141, in <module>\n",
      "    from .helpers import *\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_vendor/pyparsing/helpers.py\", line 688, in <module>\n",
      "    common_html_entity = Regex(\"&(?P<entity>\" + \"|\".join(_htmlEntityMap) + \");\").set_name(\n",
      "  File \"/project/envs/qwen-train-kernel/lib/python3.10/site-packages/pip/_vendor/pyparsing/core.py\", line 2933, in __init__\n",
      "    self.re = re.compile(self.pattern, self.flags)\n",
      "  File \"/usr/lib/python3.10/re.py\", line 251, in compile\n",
      "    return _compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.10/re.py\", line 303, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"/usr/lib/python3.10/sre_compile.py\", line 788, in compile\n",
      "    p = sre_parse.parse(p, flags)\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 955, in parse\n",
      "    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n",
      "    itemsappend(_parse(source, state, verbose, nested + 1,\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 841, in _parse\n",
      "    p = _parse_sub(source, state, sub_verbose, nested + 1)\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 444, in _parse_sub\n",
      "    itemsappend(_parse(source, state, verbose, nested + 1,\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 530, in _parse\n",
      "    subpatternappend((LITERAL, _ord(this)))\n",
      "  File \"/usr/lib/python3.10/sre_parse.py\", line 173, in append\n",
      "    def append(self, code):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/envs/qwen-train-kernel/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.9: Fast Mistral patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA H100 NVL. Num GPUs = 3. Max memory: 93.016 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "qwen_models = [\n",
    "    \"unsloth/Qwen2.5-Coder-32B-Instruct\",      # Qwen 2.5 Coder 2x faster\n",
    "    \"unsloth/Qwen2.5-Coder-7B\",\n",
    "    \"unsloth/Qwen2.5-14B-Instruct\",            # 14B fits in a 16GB card\n",
    "    \"unsloth/Qwen2.5-7B\",\n",
    "    \"unsloth/Qwen2.5-72B-Instruct\",            # 72B fits in a 48GB card\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(x):\n",
    "    clean_chat = []\n",
    "    x = eval(x)\n",
    "    for ll in x:\n",
    "        if len(ll.keys()) != 2:\n",
    "            clean_chat.append({\n",
    "                'role': ll['role'],\n",
    "                'content': ll['content'],\n",
    "            })\n",
    "        else:\n",
    "            clean_chat.append(ll)\n",
    "    return clean_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/users/nhorst/clem-project_playpen/data/training_data/DFINAL_VTrain_qwen-coder.csv\")\n",
    "df[\"conversations\"] = df[\"chat\"].map(lambda x: mapper(x))\n",
    "dataset: Dataset = Dataset.from_pandas(df=df)\n",
    "\n",
    "df_test = pd.read_csv(\"/home/users/nhorst/clem-project_playpen/data/training_data/DFINAL_VTest_qwen-coder.csv\")\n",
    "df_test[\"conversations\"] = df_test[\"chat\"].map(lambda x: mapper(x))\n",
    "dataset_test: Dataset = Dataset.from_pandas(df=df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"mistral\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7079/7079 [00:00<00:00, 10909.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7079/7079 [00:00<00:00, 7277.50 examples/s]\n",
      "Standardizing format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291/291 [00:00<00:00, 10402.91 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291/291 [00:00<00:00, 7057.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "dataset = standardize_sharegpt(dataset)\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "dataset_test = standardize_sharegpt(dataset_test)\n",
    "dataset_test = dataset_test.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a language wizard who likes to guess words by using the given rules.\\n\\nWelcome to Wordle! You have six attempts to guess the target word, a valid English word of five lowercase letters (a-z). Please use the tags \"guess:\" and \"explanation:\" to provide a concise explanation for each guess.\\n\\nTo help you make an informed guess, you will receive a clue for the word, such as\\nclue: \"snowy white\"\\n\\nHere is an example guess based on the clue:\\nguess: apple\\nexplanation: In the fairy tail Snow White, the girl is killed because she eats a poisoned apple. And the word apple has 5 letters.\\n\\nI will then indicate whether I agree or disagree with your guess and provide rationale, but agreeing with a guess does not confirm its correctness. You may choose to retain your original guess or modify it based on given clue and agreement.\\n\\nAfter each guess, your answer will be validated, and you will receive feedback indicating which letters are correct (green), which letters are correct but in the wrong position (yellow), and which letters are incorrect (red). This feedback can be useful in determining which letters to include or exclude in your next guess.\\n\\nFor example, the feedback for \"apple\" might be:\\nguess_feedback: a<yellow> p<yellow> p<green> l<yellow> e<red>\\n\\nHere are some rules to keep in mind:\\n1. Please do not generate any guess feedback or clue on your own\\n2. Use the clue, my agreement or disagreement, and guess feedback to arrive at your next guess. This should be reflected in your explanation as well.\\n\\nLet\\'s begin with your first guess.\\n\\nclue:bronze place\\n',\n",
       "  'role': 'user'},\n",
       " {'content': 'guess: third\\nexplanation: The bronze medal is awarded to the third-place finisher in competitions, so \"third\" aligns with the clue \"bronze place\" and is a five-letter word.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'clue:bronze place\\nguess_agreement:yes\\nagreement_explanation:your guess \"third\" fits the clue \"bronze place\" because the bronze medal is awarded to the third-place finisher, and \"third\" is a five-letter word.\\n',\n",
       "  'role': 'user'},\n",
       " {'content': 'guess: medal\\nexplanation: Although \"third\" fits the clue \"bronze place\" and you agreed with it, another five-letter word associated with bronze awards is \"medal.\" Since bronze medals are given to third-place finishers, \"medal\" also aligns with the clue. I\\'ll guess \"medal\" this time.',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'guess_feedback: m<red> e<red> d<yellow> a<red> l<red>',\n",
       "  'role': 'user'},\n",
       " {'content': 'guess: third\\nexplanation: Based on the clue \"bronze place\" and your agreement with my initial guess \"third,\" I believe \"third\" is still the best guess. From the feedback on \"medal,\" we know that:\\n\\n- The letter **D** is in the word but not in position 3 (since it was yellow when in position 3).\\n- Letters **M**, **E**, **A**, and **L** are not in the word.\\n\\nIn \"third,\" the **D** is in position 5, which fits the feedback. Also, all the letters in \"third\" are valid since they don\\'t include the eliminated letters. Therefore, I\\'ll guess \"third\" again.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"conversations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] You are a language wizard who likes to guess words by using the given rules.\\n\\nWelcome to Wordle! You have six attempts to guess the target word, a valid English word of five lowercase letters (a-z). Please use the tags \"guess:\" and \"explanation:\" to provide a concise explanation for each guess.\\n\\nTo help you make an informed guess, you will receive a clue for the word, such as\\nclue: \"snowy white\"\\n\\nHere is an example guess based on the clue:\\nguess: apple\\nexplanation: In the fairy tail Snow White, the girl is killed because she eats a poisoned apple. And the word apple has 5 letters.\\n\\nI will then indicate whether I agree or disagree with your guess and provide rationale, but agreeing with a guess does not confirm its correctness. You may choose to retain your original guess or modify it based on given clue and agreement.\\n\\nAfter each guess, your answer will be validated, and you will receive feedback indicating which letters are correct (green), which letters are correct but in the wrong position (yellow), and which letters are incorrect (red). This feedback can be useful in determining which letters to include or exclude in your next guess.\\n\\nFor example, the feedback for \"apple\" might be:\\nguess_feedback: a<yellow> p<yellow> p<green> l<yellow> e<red>\\n\\nHere are some rules to keep in mind:\\n1. Please do not generate any guess feedback or clue on your own\\n2. Use the clue, my agreement or disagreement, and guess feedback to arrive at your next guess. This should be reflected in your explanation as well.\\n\\nLet\\'s begin with your first guess.\\n\\nclue:bronze place\\n [/INST]guess: third\\nexplanation: The bronze medal is awarded to the third-place finisher in competitions, so \"third\" aligns with the clue \"bronze place\" and is a five-letter word.</s>[INST] clue:bronze place\\nguess_agreement:yes\\nagreement_explanation:your guess \"third\" fits the clue \"bronze place\" because the bronze medal is awarded to the third-place finisher, and \"third\" is a five-letter word.\\n [/INST]guess: medal\\nexplanation: Although \"third\" fits the clue \"bronze place\" and you agreed with it, another five-letter word associated with bronze awards is \"medal.\" Since bronze medals are given to third-place finishers, \"medal\" also aligns with the clue. I\\'ll guess \"medal\" this time.</s>[INST] guess_feedback: m<red> e<red> d<yellow> a<red> l<red> [/INST]guess: third\\nexplanation: Based on the clue \"bronze place\" and your agreement with my initial guess \"third,\" I believe \"third\" is still the best guess. From the feedback on \"medal,\" we know that:\\n\\n- The letter **D** is in the word but not in position 3 (since it was yellow when in position 3).\\n- Letters **M**, **E**, **A**, and **L** are not in the word.\\n\\nIn \"third,\" the **D** is in position 5, which fits the feedback. Also, all the letters in \"third\" are valid since they don\\'t include the eliminated letters. Therefore, I\\'ll guess \"third\" again.</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing to [\"text\"]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7079/7079 [00:02<00:00, 3537.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    #eval_dataset= dataset_test,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 1, # Fixed major bug in latest Unsloth\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 1700,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        eval_steps=100,\n",
    "        optim = \"adamw_8bit\", # Save more memory\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 7331,\n",
    "        output_dir = \"../outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7079/7079 [00:04<00:00, 1516.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"[INST]\",\n",
    "    response_part = \"[/INST]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 7,079 | Num Epochs = 3 | Total steps = 1,700\n",
      "O^O/ \\_/ \\    Batch size per device = 12 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (12 x 1 x 1) = 12\n",
      " \"-____-\"     Trainable parameters = 167,772,160/3,926,134,784 (4.27% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  62/1700 03:36 < 1:38:29, 0.28 it/s, Epoch 0.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.664800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.316700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.362100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/envs/qwen-train-kernel/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:306\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:73\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n",
      "File \u001b[0;32m/project/envs/qwen-train-kernel/lib/python3.10/site-packages/accelerate/accelerator.py:2329\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2329\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/envs/qwen-train-kernel/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/envs/qwen-train-kernel/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/envs/qwen-train-kernel/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are a language wizard who likes to guess words by using the given rules.\n",
      "\n",
      "Welcome to Wordle! You have six attempts to guess the target word, a valid English word of five lowercase letters (a-z). Please use the tags \"guess:\" and \"explanation:\" to provide a concise explanation for each guess.\n",
      "\n",
      "To help you make an informed guess, you will receive a clue for the word, such as\n",
      "clue: \"snowy white\"\n",
      "\n",
      "Here is an example guess based on the clue:\n",
      "guess: apple\n",
      "explanation: In the fairy tail Snow White, the girl is killed because she eats a poisoned apple. And the word apple has 5 letters.\n",
      "\n",
      "I will then indicate whether I agree or disagree with your guess and provide rationale, but agreeing with a guess does not confirm its correctness. You may choose to retain your original guess or modify it based on given clue and agreement.\n",
      "\n",
      "After each guess, your answer will be validated, and you will receive feedback indicating which letters are correct (green), which letters are correct but in the wrong position (yellow), and which letters are incorrect (red). This feedback can be useful in determining which letters to include or exclude in your next guess.\n",
      "\n",
      "For example, the feedback for \"apple\" might be:\n",
      "guess_feedback: a<yellow> p<yellow> p<green> l<yellow> e<red>\n",
      "\n",
      "Here are some rules to keep in mind:\n",
      "1. Please do not generate any guess feedback or clue on your own\n",
      "2. Use the clue, my agreement or disagreement, and guess feedback to arrive at your next guess. This should be reflected in your explanation as well.\n",
      "\n",
      "Let's begin with your first guess.\n",
      "\n",
      "clue:bronze place\n",
      " [/INST]guess: third\n",
      "explanation: The bronze medal is awarded to the third-place finisher in competitions, so \"third\" aligns with the clue \"bronze place\" and is a five-letter word.</s>[INST] clue:bronze place\n",
      "guess_agreement:yes\n",
      "agreement_explanation:your guess \"third\" fits the clue \"bronze place\" because the bronze medal is awarded to the third-place finisher, and \"third\" is a five-letter word.\n",
      " [/INST]guess: medal\n",
      "explanation: Although \"third\" fits the clue \"bronze place\" and you agreed with it, another five-letter word associated with bronze awards is \"medal.\" Since bronze medals are given to third-place finishers, \"medal\" also aligns with the clue. I'll guess \"medal\" this time.</s>[INST] guess_feedback: m<red> e<red> d<yellow> a<red> l<red> [/INST]guess: third\n",
      "explanation: Based on the clue \"bronze place\" and your agreement with my initial guess \"third,\" I believe \"third\" is still the best guess. From the feedback on \"medal,\" we know that:\n",
      "\n",
      "- The letter **D** is in the word but not in position 3 (since it was yellow when in position 3).\n",
      "- Letters **M**, **E**, **A**, and **L** are not in the word.\n",
      "\n",
      "In \"third,\" the **D** is in position 5, which fits the feedback. Also, all the letters in \"third\" are valid since they don't include the eliminated letters. Therefore, I'll guess \"third\" again.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"<s>[INST] You are a language wizard who likes to guess words by using the given rules.\n",
    "\n",
    "Welcome to Wordle! You have six attempts to guess the target word, a valid English word of five lowercase letters (a-z). Please use the tags \"guess:\" and \"explanation:\" to provide a concise explanation for each guess.\n",
    "\n",
    "To help you make an informed guess, you will receive a clue for the word, such as\n",
    "clue: \"snowy white\"\n",
    "\n",
    "Here is an example guess based on the clue:\n",
    "guess: apple\n",
    "explanation: In the fairy tail Snow White, the girl is killed because she eats a poisoned apple. And the word apple has 5 letters.\n",
    "\n",
    "I will then indicate whether I agree or disagree with your guess and provide rationale, but agreeing with a guess does not confirm its correctness. You may choose to retain your original guess or modify it based on given clue and agreement.\n",
    "\n",
    "After each guess, your answer will be validated, and you will receive feedback indicating which letters are correct (green), which letters are correct but in the wrong position (yellow), and which letters are incorrect (red). This feedback can be useful in determining which letters to include or exclude in your next guess.\n",
    "\n",
    "For example, the feedback for \"apple\" might be:\n",
    "guess_feedback: a<yellow> p<yellow> p<green> l<yellow> e<red>\n",
    "\n",
    "Here are some rules to keep in mind:\n",
    "1. Please do not generate any guess feedback or clue on your own\n",
    "2. Use the clue, my agreement or disagreement, and guess feedback to arrive at your next guess. This should be reflected in your explanation as well.\n",
    "\n",
    "Let's begin with your first guess.\n",
    "\n",
    "clue:bronze place\n",
    " [/INST]guess: third\n",
    "explanation: The bronze medal is awarded to the third-place finisher in competitions, so \"third\" aligns with the clue \"bronze place\" and is a five-letter word.</s>[INST] clue:bronze place\n",
    "guess_agreement:yes\n",
    "agreement_explanation:your guess \"third\" fits the clue \"bronze place\" because the bronze medal is awarded to the third-place finisher, and \"third\" is a five-letter word.\n",
    " [/INST]guess: medal\n",
    "explanation: Although \"third\" fits the clue \"bronze place\" and you agreed with it, another five-letter word associated with bronze awards is \"medal.\" Since bronze medals are given to third-place finishers, \"medal\" also aligns with the clue. I'll guess \"medal\" this time.</s>[INST] guess_feedback: m<red> e<red> d<yellow> a<red> l<red> [/INST]guess: third\n",
    "explanation: Based on the clue \"bronze place\" and your agreement with my initial guess \"third,\" I believe \"third\" is still the best guess. From the feedback on \"medal,\" we know that:\n",
    "\n",
    "- The letter **D** is in the word but not in position 3 (since it was yellow when in position 3).\n",
    "- Letters **M**, **E**, **A**, and **L** are not in the word.\n",
    "\n",
    "In \"third,\" the **D** is in position 5, which fits the feedback. Also, all the letters in \"third\" are valid since they don't include the eliminated letters. Therefore, I'll guess \"third\" again.</s>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-kernel",
   "language": "python",
   "name": "qwen-train-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
